import faiss
import numpy as np
from sentence_transformers import SentenceTransformer, CrossEncoder

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
retrieval_model = SentenceTransformer("all-MiniLM-L6-v2")  # –î–ª—è –ø–æ–∏—Å–∫–∞
reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")  # –î–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è


# –ò—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
documents = [
    "LLM –º–æ–≥—É—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.",
    "–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–µ–Ω —á–µ—Ä–µ–∑ BM25 –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫.",
    "–ì–ª—É–±–æ–∫–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ø–æ–º–æ–≥–∞—é—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç.",
    "RAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞."
]

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
doc_embeddings = retrieval_model.encode(documents)
dimension = doc_embeddings.shape[1]

# –°–æ–∑–¥–∞—ë–º FAISS –∏–Ω–¥–µ–∫—Å
index = faiss.IndexFlatL2(dimension)
index.add(np.array(doc_embeddings))

# –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
query = "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∏—Å–∫ –≤ RAG?"
query_embedding = retrieval_model.encode([query])

# –ü–æ–∏—Å–∫ 3 –±–ª–∏–∂–∞–π—à–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
D, I = index.search(np.array(query_embedding), k=3)
retrieved_docs = [documents[idx] for idx in I[0]]

# –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
scores = reranker.predict([(query, doc) for doc in retrieved_docs])
ranked_docs = [doc for _, doc in sorted(zip(scores, retrieved_docs), reverse=True)]

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–ø–æ—Å–ª–µ –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∫–∏):")
for doc in ranked_docs:
    print(f"- {doc}")

